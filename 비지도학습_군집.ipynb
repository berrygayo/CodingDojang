{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "비지도학습-군집.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPmB8wqGbuDIjtxHmdD9Pkq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/berrygayo/CodingDojang/blob/master/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5_%EA%B5%B0%EC%A7%91.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzoXsqnWY2BL"
      },
      "source": [
        "# 군집\n",
        "+ 군집은 데이터셋을 클러스터라는 그룹으로 나누는 작업 \n",
        "+ 한 클러스터 안의 데이터 포인트끼리는 매우 비슷하고 다른 클러스터의 데이터 포인트와는 구분되도록 데이터를 나누는 것이 목"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dazAB9UaoKA"
      },
      "source": [
        "## k-평균 군집 \n",
        "+ 가장 간단하고 널리 사용하는 군집 알고리즘 \n",
        "+ 데이터의 어떤 영역을 대표하는 클러스터 중심을 찾는다 \n",
        "\n",
        "> 두 단계를 반복한다 \n",
        "\n",
        "1. 데이터 포인트를 가장 가까운 클러스터 중심에 할당 \n",
        "2. 클러스테 할당된 데이터 포인트의 평균으로 클러스터 중심을 다시 저장 \n",
        "3. 1,2 반복하고 클러스터에 할당되는 데이터 포인트에 변화가 없을 때 알고리즘이 종료됩니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNXPfUW0mk0O"
      },
      "source": [
        "!pip install mglearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PooLQVSNbK2G"
      },
      "source": [
        "import mglearn\n",
        "mglearn.plots.plot_kmeans_algorithm()\n",
        "\n",
        "# 1. 각 데이터 포인트를 가까운 클러스터에 할당 \n",
        "#2. 할당한 포인트의 평균값으로 클러스터 중심을 갱싱 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "safsNWMnbYeG"
      },
      "source": [
        "mglearn.plots.plot_kmeans_boundaries()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwywF7jzbPmm"
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# 인위적으로 2차원 데이터를 생성합니다\n",
        "X, y = make_blobs(random_state=1)\n",
        "\n",
        "# 군집 모델을 만듭니다\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEW9jfJybK4m"
      },
      "source": [
        "# 알고리즘을 적용하면 x에 담긴 각 훈련 데이터 포인트에 클러스터 레이블이 할당된다. \n",
        "print(kmeans.labels_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGoFVIXucX7P"
      },
      "source": [
        "# predict 메서드를 사용해 새로운 데이터의 클러스터 레이블을 예측할 수 있다. \n",
        "# 예측은 각 포인트에 가장 가까운 클러스터 중심을 할당하는 것이며 기존 모델을 변경하지 않는다. \n",
        "print(kmeans.predict(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr8TTDGncjNX"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "mglearn.discrete_scatter(X[:, 0], X[:, 1], kmeans.labels_, markers='o')\n",
        "mglearn.discrete_scatter(\n",
        "    kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], [0, 1, 2],\n",
        "    markers='^', markeredgewidth=2)\n",
        "plt.show() # 책에는 없음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xXCG4O_d4lG"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "# 두 개의 클러스터 중심을 사용합니다\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(X)\n",
        "assignments = kmeans.labels_\n",
        "\n",
        "mglearn.discrete_scatter(X[:, 0], X[:, 1], assignments, ax=axes[0])\n",
        "\n",
        "# 다섯 개의 클러스터 중심을 사용합니다\n",
        "kmeans = KMeans(n_clusters=5)\n",
        "kmeans.fit(X)\n",
        "assignments = kmeans.labels_\n",
        "\n",
        "mglearn.discrete_scatter(X[:, 0], X[:, 1], assignments, ax=axes[1])\n",
        "plt.show() # 책에는 없음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I_PGG7vbK6s"
      },
      "source": [
        "## k-평균 알고리즘이 실패하는 경우 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrHZaUQCbK9N"
      },
      "source": [
        "X_varied, y_varied = make_blobs(n_samples=200,\n",
        "                                cluster_std=[1.0, 2.5, 0.5],\n",
        "                                random_state=170)\n",
        "y_pred = KMeans(n_clusters=3, random_state=0).fit_predict(X_varied)\n",
        "\n",
        "mglearn.discrete_scatter(X_varied[:, 0], X_varied[:, 1], y_pred)\n",
        "plt.legend([\"클러스터 0\", \"클러스터 1\", \"클러스터 2\"], loc='best')\n",
        "plt.xlabel(\"특성 0\")\n",
        "plt.ylabel(\"특성 1\")\n",
        "plt.show() # 책에는 없음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPn5qv2QeqCS"
      },
      "source": [
        "import numpy as np \n",
        "# 무작위로 클러스터 데이터 생성합니다\n",
        "X, y = make_blobs(random_state=170, n_samples=600)\n",
        "rng = np.random.RandomState(74)\n",
        "\n",
        "# 데이터가 길게 늘어지도록 변경합니다\n",
        "transformation = rng.normal(size=(2, 2))\n",
        "X = np.dot(X, transformation)\n",
        "\n",
        "# 세 개의 클러스터로 데이터에 KMeans 알고리즘을 적용합니다\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(X)\n",
        "y_pred = kmeans.predict(X)\n",
        "\n",
        "# 클러스터 할당과 클러스터 중심을 나타냅니다\n",
        "mglearn.discrete_scatter(X[:, 0], X[:, 1], kmeans.labels_, markers='o')\n",
        "mglearn.discrete_scatter(\n",
        "    kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], [0, 1, 2],\n",
        "    markers='^', markeredgewidth=2)\n",
        "plt.xlabel(\"특성 0\")\n",
        "plt.ylabel(\"특성 1\")\n",
        "plt.show() # 책에는 없음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtuL0g4petQQ"
      },
      "source": [
        "# two_moons 데이터를 생성합니다(이번에는 노이즈를 조금만 넣습니다)\n",
        "from sklearn.datasets import make_moons\n",
        "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
        "\n",
        "# 두 개의 클러스터로 데이터에 KMeans 알고리즘을 적용합니다\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(X)\n",
        "y_pred = kmeans.predict(X)\n",
        "\n",
        "# 클러스터 할당과 클러스터 중심을 표시합니다\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap=mglearn.cm2, s=60, edgecolors='k')\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
        "            marker='^', c=[mglearn.cm2(0), mglearn.cm2(1)], s=100, linewidth=2, edgecolors='k')\n",
        "plt.xlabel(\"특성 0\")\n",
        "plt.ylabel(\"특성 1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG3CY3epe3GO"
      },
      "source": [
        "# DBSCAN \n",
        "+ 주요 장점은 클러스터의 개수를 미리 지정할 피요가 없다는 점이다.\n",
        "+ 복잡한 형상도 찾을 수 있으며, 어떤 클래스에도 속하지 않는 포인트를 구분할 수 있다.\n",
        "+ k-평균 보다는 다소 느리지만 비교적 큰 데이터셋에도 적용할 수 있다.\n",
        "\n",
        "밀집 지역에 있는 포인트를 핵심 샘플(또는 핵심 포인트)라고 하며 다음과 같이 정의한다. \n",
        "DBSCAN에는 두 개의 매개변수 min_samples 와 eps가 있습니다.\n",
        "한 데이터 포인트에서 eps 거리 안에 데이터가 min_samples 개수만큼 들어 있으면 이 데이터 포인트를 핵심 샘플로 분류합니다.\n",
        " eps보다 가까운 핵심 샘플은 DBSCAN에 의해 동일한 클러스터로 합쳐진다.\n",
        "\n",
        " > 포인트의 종류는 세가지이다. \n",
        "+ 핵심 포인트, 경계 포인트(핵심 포인트에서 eps거리 안에 있는 포인트), 잡음 포인트 \n",
        "\n",
        "DBSCAN을 한 데이터셋에 여러 번 실행하면 핵심 포인트의 군집은 항상 같ㄷ고 매번 같은 ㅍ인트를 잡음으로 레이블한다. 그러나 경계 포인트는 한 개 이상의 클러스터 핵심 샘플의 이웃일 수 있습니다. 그렇기 때문에 경계 포인트가 어떤 클러스터에 속할지는 포인트를 방문하는 순서에 따라 달라집니다. 보통 경계포인트는 많지 않으며 포인트 순서 때문에 바든 영향도 적어 중요한 이슈는 아닙니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNWFC-cje3Ik"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "X, y = make_blobs(random_state=0, n_samples=12)\n",
        "\n",
        "dbscan = DBSCAN()\n",
        "clusters = dbscan.fit_predict(X)\n",
        "print(\"클러스터 레이블:\\n\", clusters)\n",
        "# 모든 포인트에 잡음 포인트를 의미하는 -1 레이블이 할당되었다.\n",
        "# 이는 작은 샘플 데이터셋에 적합하지 않ㅇ느 eps와 min_samples 기본값 때문이다. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCMQpb-xe3Kl"
      },
      "source": [
        "# min_samples 와 eps 에 따른 클러스터 할당 \n",
        "mglearn.plots.plot_dbscan()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK6MRSFOlty7"
      },
      "source": [
        "> 그래프 해석 \n",
        "\n",
        "클러스터에 속한 포인트는 색을 칠하고 잡음 포인트는 하얀색으로 남겨두었다.\n",
        "핵심 샘플은 크게, 경계 포인트는 작게 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c95zf_ce3M1"
      },
      "source": [
        "# two monn 데이터셋에 적용 \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
        "\n",
        "# 평균이 0, 분산이 1이 되도록 데이터의 스케일을 조정합니다\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X_scaled = scaler.transform(X)\n",
        "\n",
        "dbscan = DBSCAN()\n",
        "clusters = dbscan.fit_predict(X_scaled)\n",
        "# 클러스터 할당을 표시합니다\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap=mglearn.cm2, s=60, edgecolors='black')\n",
        "plt.xlabel(\"특성 0\")\n",
        "plt.ylabel(\"특성 1\")\n",
        "plt.show() # 책에는 없음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-zg3neMyUp4"
      },
      "source": [
        "## 군집 알고리즘의 비교와 평가 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcymKkewe3O2"
      },
      "source": [
        "### 타켓값으로 군집 평가하기\n",
        "\n",
        "+ ARI : 1(최적일 때)과 0(주막위로 분류될 때) 사이의 값을 제공 \n",
        "+ NMI \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS9ai_Xx1GnS"
      },
      "source": [
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
        "\n",
        "# 평균이 0, 분산이 1이 되도록 데이터의 스케일을 조정합니다\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X_scaled = scaler.transform(X)\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(15, 3),\n",
        "                         subplot_kw={'xticks': (), 'yticks': ()})\n",
        "\n",
        "# 사용할 알고리즘 모델을 리스트로 만듭니다\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "algorithms = [KMeans(n_clusters=2), AgglomerativeClustering(n_clusters=2),\n",
        "              DBSCAN()]\n",
        "\n",
        "# 비교를 위해 무작위로 클러스터 할당을 합니다\n",
        "random_state = np.random.RandomState(seed=0)\n",
        "random_clusters = random_state.randint(low=0, high=2, size=len(X))\n",
        "\n",
        "# 무작위 할당한 클러스터를 그립니다\n",
        "axes[0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=random_clusters,\n",
        "                cmap=mglearn.cm3, s=60, edgecolors='black')\n",
        "axes[0].set_title(\"무작위 할당 - ARI: {:.2f}\".format(\n",
        "        adjusted_rand_score(y, random_clusters)))\n",
        "\n",
        "for ax, algorithm in zip(axes[1:], algorithms):\n",
        "    # 클러스터 할당과 클러스터 중심을 그립니다\n",
        "    clusters = algorithm.fit_predict(X_scaled)\n",
        "    ax.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters,\n",
        "               cmap=mglearn.cm3, s=60, edgecolors='black')\n",
        "    ax.set_title(\"{} - ARI: {:.2f}\".format(algorithm.__class__.__name__,\n",
        "                                           adjusted_rand_score(y, clusters)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twzjJnYGnznH"
      },
      "source": [
        "> 해석 \n",
        "\n",
        "클러스터를 무작위로 할당했을 때의 ARI 점수는 0이고, DBSCAN은 점수가 1이다.\n",
        "군집 모델을 평가할 때 흔히 하는 실수가 adjusted_rand_score나 normalized_mutual_info_score 같은 군집용 측정 도구를 사용하지 않고 accuracy_score를 사용하는 것이다. \n",
        "정확도를 사용하면 할당된 클러스터의 레이블 이름과 실제 레이블 이름과 맞는지 확인합니다.\n",
        "그러나 클러스터 레이블은 그 자체로 의미가 있는 것이 아니며 포인트들이 같은 클러스터에 속해 있는가만이 중요하다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lxvmDuh1GpL"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 포인트가 클러스터로 나뉜 두 가지 경우\n",
        "clusters1 = [0, 0, 1, 1, 0]\n",
        "clusters2 = [1, 1, 0, 0, 1]\n",
        "# 모든 레이블이 달라졌으므로 정확도는 0입니다\n",
        "# accuracy는 군집에서 사용하지 말 것 ! \n",
        "print(\"정확도: {:.2f}\".format(accuracy_score(clusters1, clusters2)))\n",
        "# 같은 포인트가 클러스터에 모였으므로 ARI는 1입니다\n",
        "print(\"ARI: {:.2f}\".format(adjusted_rand_score(clusters1, clusters2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcAdx-if1GrT"
      },
      "source": [
        "### 타겟값 없이 군집 평가하기 \n",
        "\n",
        "+ 실루엣 계수 : 타깃값이 필요 없는 군집용 지표 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaBv-pK11Mg2"
      },
      "source": [
        "from sklearn.metrics.cluster import silhouette_score\n",
        "\n",
        "X, y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
        "\n",
        "# 평균이 0, 분산이 1이 되도록 데이터의 스케일을 조정합니다\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X_scaled = scaler.transform(X)\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(15, 3),\n",
        "                         subplot_kw={'xticks': (), 'yticks': ()})\n",
        "\n",
        "# 비교를 위해 무작위로 클러스터 할당을 합니다\n",
        "random_state = np.random.RandomState(seed=0)\n",
        "random_clusters = random_state.randint(low=0, high=2, size=len(X))\n",
        "\n",
        "# 무작위 할당한 클러스터를 그립니다\n",
        "axes[0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=random_clusters,\n",
        "                cmap=mglearn.cm3, s=60, edgecolors='black')\n",
        "axes[0].set_title(\"무작위 할당: {:.2f}\".format(\n",
        "        silhouette_score(X_scaled, random_clusters)))\n",
        "\n",
        "algorithms = [KMeans(n_clusters=2), AgglomerativeClustering(n_clusters=2),\n",
        "              DBSCAN()]\n",
        "\n",
        "for ax, algorithm in zip(axes[1:], algorithms):\n",
        "    clusters = algorithm.fit_predict(X_scaled)\n",
        "    # 클러스터 할당과 클러스터 중심을 그립니다\n",
        "    ax.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap=mglearn.cm3,\n",
        "               s=60, edgecolors='black')\n",
        "    ax.set_title(\"{} : {:.2f}\".format(algorithm.__class__.__name__,\n",
        "                                      silhouette_score(X_scaled, clusters)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIMXqx_11Mi0"
      },
      "source": [
        "> 해석 \n",
        "\n",
        "이 그림에서 볼 수 있듯이 DBSCAN의 결과가 더 낫지만 k-평균 의 실루엣 점수가 더 높다. \n",
        "클러스터 평가에 더 적합한 전략은 경고성 기반의 지표입니다.\n",
        "데이터에 잡음 포인트를 추가하거나 여러 가지 매개변수 설정으로 알고리즘을 실행하고 그 결과를 비교하는 것입니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0Ucwnv31Mk3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}